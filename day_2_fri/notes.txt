Pydantic validation is the most widely used data validation library in python.

pydantic log fire is a monitory tool that we can use to monitor pydantic validaiton and understand shy some input fail validaiton 

Why use Pydantic?¶
  - Powered by type hints — with Pydantic, schema validation and serialization are controlled by type annotations; less to learn, less code to write, and integration with your IDE and static analysis tools. Learn more…
  - Speed — Pydantic's core validation logic is written in Rust. As a result, Pydantic is among the fastest data validation libraries for Python. Learn more…
  - JSON Schema — Pydantic models can emit JSON Schema, allowing for easy integration with other tools. Learn more…
  - Strict and Lax mode — Pydantic can run in either strict mode (where data is not converted) or lax mode where Pydantic tries to coerce data to the correct type where appropriate. Learn more…
  - Dataclasses, TypedDicts and more — Pydantic supports validation of many standard library types including dataclass and TypedDict. Learn more…
  - Customisation — Pydantic allows custom validators and serializers to alter how data is processed in many powerful ways. Learn more…
  - Ecosystem — around 8,000 packages on PyPI use Pydantic, including massively popular libraries like FastAPI, huggingface, Django Ninja, SQLModel, & LangChain. Learn more…
  - Battle tested — Pydantic is downloaded over 360M times/month and is used by all FAANG companies and 20 of the 25 largest companies on NASDAQ. If you're trying to do something with Pydantic, someone else has probably already done it. Learn more…


----    NOTE: WE ARE ALWAYS USING SQUARE BRACKETS IN THE TYPES

Everything in Pydantic revolves around creating classes that inherit from BaseModel. You use standard Python type hints to define exactly what your data should look like.

from pydantic import BaseModel

class User(BaseModel):
    id: int
    username: str
    is_active: bool


note: one asteriks "*" is used for list and tuples unpacking, and double astriks "**" is used for dictionaris unpacking 


Here are the absolute base concepts you need to know to master it.

---

### 1. The `BaseModel` (The Blueprint)

Everything in Pydantic revolves around creating classes that inherit from `BaseModel`. You use standard Python type hints to define exactly what your data should look like.

```python
from pydantic import BaseModel

class User(BaseModel):
    id: int
    username: str
    is_active: bool

```

That’s it. You just built a data validator.

### 2. Type Coercion (The Magic Trick)

Pydantic is not just a validator; it is a **parser**. Pydantic guarantees the *output* type, which means it will actively try to fix your data if it can.

Look at what happens if we pass messy data (like you might get from a web form or a sloppy CSV file) into our `User` model:

```python
# The input data is messy: 'id' is a string, 'is_active' is a string
messy_data = {
    "id": "105", 
    "username": "data_ninja", 
    "is_active": "yes"
}

# Unpack the dictionary into the Pydantic model
new_user = User(**messy_data)

print(repr(new_user.id))         # Output: 105 (Converted to int!)
print(repr(new_user.is_active))  # Output: True (Converted to bool!)

```

Pydantic saw the string `"105"` and cleanly converted it to the integer `105`. It saw `"yes"` and knew that meant `True`.

### 3. Handling Bad Data (`ValidationError`)

If Pydantic *cannot* fix the data, it throws a massive stop sign called a `ValidationError`. This is fantastic for data pipelines because you want bad data to fail loudly and clearly before it corrupts your database.

```python
from pydantic import ValidationError

bad_data = {
    "id": "twenty",  # Fails: cannot convert words to integers
    "username": "data_ninja",
    "is_active": True
}

try:
    user = User(**bad_data)
except ValidationError as e:
    print(e)

```

**The Output:**
Pydantic will tell you exactly which field failed, what you passed in, and why it failed:

> `1 validation error for User`
> `id`
> `Input should be a valid integer, unable to parse string as an integer [type=int_parsing]`

### 4. Optional Fields and Default Values

Real-world data is rarely complete. If you don't provide a required field, Pydantic will throw an error. You manage missing data using standard Python defaults.

```python
class Employee(BaseModel):
    id: int
    name: str
    # Has a default value, so providing it is optional
    department: str = "Engineering" 
    # Can be a string OR None. Defaults to None.
    manager_name: str | None = None 

# We only provide the strict requirements
emp = Employee(id=1, name="Alice")

print(emp.department)   # Output: 'Engineering'
print(emp.manager_name) # Output: None

```

*(Note: In older Python versions, you might see `Optional[str]` used instead of `str | None`)*

### 5. Ingesting and Exporting Data (The Pipeline)

In Data Engineering, you are constantly ingesting JSON from an API, validating it, and then spitting it back out to save into a database. Pydantic makes this seamless.

* **To create a model from a dictionary:** `User(**my_dict)`
* **To create a model from a raw JSON string:** `User.model_validate_json(my_json_string)`

Once the data is safely inside the model, you can export it just as easily:

* **Export back to a Python dictionary:** `new_user.model_dump()`
* **Export straight to a JSON string:** `new_user.model_dump_json()`

*(Note: If you look at older tutorials, you might see `.dict()` and `.json()`. Pydantic V2 updated these to `.model_dump()` and `.model_dump_json()` to avoid interfering with fields you might actually want to name "dict").*


===============================

        SUMMARY 

===============================


### 1. The Blueprint: `BaseModel` & Type Coercion

Pydantic uses standard Python type hints to validate and automatically coerce (fix) messy data.

```python
from pydantic import BaseModel

class User(BaseModel):
    id: int
    is_active: bool = True # Default value makes it optional

# Coercion in action: fixes the string "123" into an integer 123
user = User(id="123") 

```

### 2. Strict Mode (The "Mean Bouncer")

Disables automatic type coercion. If the data type doesn't match exactly, it throws a `ValidationError`.

```python
# Fails because "123" is a string, not an int
user = User.model_validate({"id": "123"}, strict=True) 

```

### 3. Ingesting Data (Input Methods)

Always choose the right method based on the source data format to optimize memory and speed.

* **`.model_validate(dictionary)`**: Used when data is already a Python dictionary (e.g., fetched from a database using `psycopg2`).
* **`.model_validate_json(raw_string)`**: The high-speed Rust pipeline. Parses a raw JSON string directly into an object without creating a temporary dictionary. Essential for API payloads and massive files.

### 4. Exporting Data (Serialization)

Getting validated data back out into dictionaries or JSON strings.

* **`.model_dump()`**: Returns a Python dictionary.
* `mode='json'`: Forces Python-specific objects (like `datetime` or `bytes`) into JSON-safe strings.
* `exclude_unset=True`: Only exports fields the user actually provided (crucial for API `PATCH` updates).
* `exclude={'field_name'}`: Strips specific fields from the output.


* **`.model_dump_json()`**: Skips the dictionary step and returns a raw JSON string.

### 5. TypeAdapter (Validating Without Classes)

Validates raw Python types (lists, dicts, `TypedDict`) when you don't need a full `BaseModel` object.

```python
from pydantic import TypeAdapter

# Validates a raw list of integers
adapter = TypeAdapter(list[int])
clean_list = adapter.validate_json('[1, "2", 3]') # Returns Python list: [1, 2, 3]

```

### 6. Data Contracts: JSON Schema

Generates an industry-standard metadata document describing exactly what your model expects. Used to share data structures with frontend teams or generate OpenAPI/Swagger docs.

```python
schema = User.model_json_schema()

```

### 7. Custom Validators (The `wrap` Mode)

Allows you to intercept data to run custom logic *before* and *after* Pydantic's internal validation (`handler`). Perfect for standardizing messy inputs like timezones or custom keywords.

```python
from typing import Any
from datetime import datetime
from pydantic import BaseModel, field_validator
from pydantic_core.core_schema import ValidatorFunctionWrapHandler

class Event(BaseModel):
    when: datetime

    @field_validator('when', mode='wrap')
    def parse_custom_dates(cls, value: Any, handler: ValidatorFunctionWrapHandler):
        if value == 'now':                 # Custom logic BEFORE validation
            return datetime.now()
        
        parsed_date = handler(value)       # Pydantic's internal validation
        
        return parsed_date                 # Return the final cleaned data

```