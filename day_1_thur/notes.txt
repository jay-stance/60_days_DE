iterators is fundamental in data processing, and when fetching items that don't fit into memory we need a way to fetch them dizzly, that is one at a time, or on demand

the yield keyword allows the construction of generators which works as iterators. iterators retrieves things from collections, but generators can retrieve things form thin air

whenever the interpreter needs to iterate over an object, it automatically calls the iter(x) built in function
the iter(s) built in function
- check weither the object implements iter and calls that to gat an iterator 
- if __iter__ is not implmeneted but __getItem__ is, python creates an iterator that attempts to fetch items in order starting from index 0 
- if that also fails, python raises type error, usually 'object is not an iterable'

a core philosophy of Python called EAFP ("Easier to Ask for Forgiveness than Permission").

instead of using isInstance or isSubclass abc.iterable to check if an object is iterable, use iter(X), as this checks not as strict as the lateer. it tries to create an actual iterator from the object, meaning it checks for iter and get item functions. just checks if it walks like a duck 

the standrd interface for an iterator has 2 methods:
- __next__: returns next available items until stop iteration error is raised
- __iter__: returns self, allows iterators to be used where an iterable is expected. eg using an already created iterator or generator in for loops, the for loop always tries to call iter on whatever it is passed, and now remember we passed an already generated iterator. so if this iterator doesn't have an iter in it too, the for loop would crash 

iterable - __iter__

iterator - __next__
         - __iter__  - returns self      (this now means in iterator can be used wherever an iterable is required )



Here are the key takeaways you need to remember about this `Iterator` class code. Think of this as the "Constitution" for all Python iterators.

* **Inheritance Hierarchy (`Iterator(Iterable)`):**
* Every Iterator is technically an Iterable (a child of the `Iterable` class).
* This means anything you can call `next()` on, you can also loop over in a `for` loop.


* **The "Must-Do" Rule (`@abstractmethod __next__`):**
* This is an abstract method. It enforces that if you build a custom iterator, **you** are responsible for writing the logic to fetch the next item.
* The base class does *not* know how to fetch your data. It just defines the rule that you must raise `StopIteration` when there is no data left.


* **The "Free Gift" (`def __iter__`):**
* This method is already written for you. It returns `self`.
* **Takeaway:** When you write a custom iterator class that inherits from this, you **do not** need to write `__iter__`. You get this behavior for free. It ensures your iterator works in `for` loops immediately.


* **Memory Efficiency (`__slots__ = ()`):**
* This class is designed to be lightweight.
* It explicitly refuses to create a `__dict__` (backpack) to save memory, as it is just a blueprint and shouldn't store data itself.


* **Duck Typing Logic (`__subclasshook__`):**
* This is the "Honorary Citizen" rule.
* It tells Python: "Even if a class didn't explicitly inherit from me (`class X(Iterator)`), if it has both `__iter__` and `__next__` methods, treat it as an Iterator anyway."
* This allows `isinstance(my_object, Iterator)` to return `True` for objects that just *look* like iterators, keeping Python flexible.

becuase the only functions that are required are __iter__ and __next__ there is no way to know remaining items in an iterator, or even to reset the iterator. to reset you must call iterator on the iterable that created the iterator and not the iterator itself, cos the __iter__ returned by the iterator itself is basically just itself, meaning no reset.

iterables always returns a new iterator when instatiated, while iterators return self, and a next function 

NOTE: don't be tempted to put the iterator generator inside the main class, it would. make it exhaustible, as you would be reading the main class' state.

These are instances when you should use the generate iterator method 
- o access an aggregate object’s contents without exposing its internal representation.
  so you just call next wihtout having to know how the object is handling the data, weither it is downloading it, fetching it, running a query, you don't need to know all those 
• to support multiple traversals of aggregate objects.
  so that multiple objects can read the same object with them having different pointers and not affecthign the other's state, as they are the ones managing their individual states.
  To “support multiple traversals” it must be possible to obtain multiple independent
  iterators from the same iterable instance, and each iterator must keep its own internal
  state,
• to provide a uniform interface for traversing different aggregate structures (that is,
to support polymorphic iteration).
  so we have a uniform way of iterating through data types, so we don't need to learn new ways for different data types 


  ===============================

           GENERATORS 

  ===============================


Any python funciton that has the yield keyword in its body is a generator function, a function which when called returns a generator object 
with generator funcitons, function body is suspended as they yield, and then returns when they are done yielding. he return statement in the body
of a generator function causes StopIteration to be raised by the
generator object.8

Nowadays, laziness is considered a good trait, at least in programming lan‐
guages and APIs. A lazy implementation postpones producing values to the last possible
moment. This saves memory and may avoid useless processing as well.

THAT IS TO SAY, GENERATORS IS A NICE WAY OF SAVING MEMORY 

A generator expression is a lazy version of a list comprehension.